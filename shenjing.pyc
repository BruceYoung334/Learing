#!/usr/bin/env python
# coding: utf-8

# This notebook is about Principal Component Analysis. 

# Importing relevant packages

# In[2]:


import os
import matplotlib.pyplot as plt
import geopandas
import pandas as pd
import seaborn as sn
import numpy as np
from pyspatialml import Raster


# In[3]:


from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.model_selection import cross_validate
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.decomposition import PCA


# In[34]:


from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import normalize, scale
from sklearn.preprocessing import StandardScaler
from bayes_opt import BayesianOptimization
from hyperopt import fmin, tpe, hp, STATUS_OK, Trials
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import RandomizedSearchCV
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error
from pprint import pprint
import pandas as pd
import numpy as np
import xgboost as xgb
import lightgbm as lgb
import json
from sklearn import svm
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
import seaborn as sns
from sklearn.linear_model import LogisticRegression
from sklearn import metrics
from sklearn.model_selection import train_test_split,StratifiedKFold,cross_val_score,GridSearchCV,learning_curve
from sklearn.metrics import confusion_matrix,classification_report,accuracy_score,roc_curve,roc_auc_score,auc,precision_recall_curve,average_precision_score
from xgboost import XGBClassifier
from lightgbm.sklearn import LGBMClassifier


# Setting up the directory

# In[35]:


os.chdir(r'C:\Users\monster\Desktop\vacation\machine learning\Variables')


# Loading the data (landslide presence/absebce points)

# In[36]:


data=pd.read_csv('sample_points.csv')


# In[37]:


data.head()


# Dropping categorical columns

# In[38]:


data = data.drop(columns=['soil', 'geomorphology', 'underground', 'prequaternary'])


# Separating features from labels

# In[39]:


X = data.iloc[:, 0:-1]


# In[40]:


y = data["class"]


# Splitting the data into training (70%) and testing (30%)

# In[41]:


X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3, random_state=42,stratify=y)


# Standardizing the data before PCA

# In[42]:


scaler=StandardScaler().fit(X_train)
standardized_train_data = scaler.transform(X_train)


# Creating a PCA model. 16 Principal Components are chosen, because they retain 95% of variance in our data. It reduces the dimensionality of our dataset from 28 to 16 dimensions

# In[43]:


pca_model = PCA(n_components=16)
pc_train_data= pca_model.fit_transform(standardized_train_data)


# In[44]:


# like we did above visualize the PCs 
# and the cumulative variance explained by each PC

plt.bar(range(1,17), pca_model.explained_variance_ratio_,
        alpha=1,
        align='center',
       color='blue')
plt.step(range(1,17), np.cumsum(pca_model.explained_variance_ratio_),
         where='mid',
         color='red')
plt.ylabel('Explained variance ratio')
plt.xlabel('Principal Components')
#plt.savefig(r'C:\Users\monster\Desktop\Variables\variance_pca.png', bbox_inches='tight', dpi=600)
plt.show()


# In[45]:


pca_model.explained_variance_ratio_


# In[46]:


pca_model.explained_variance_ratio_.cumsum()


# The first component captures around 27% of variability in our data, while the second component - around 15% and so on.
# 16 Principal Components explain around 97% of the variability in the data

# In[47]:


# component loadings or weights (correlation coefficient between original variables and the component) 
# component loadings represent the elements of the eigenvector
# the squared loadings within the PCs always sums to 1
#components_ attribute provides principal axes in feature space,
#representing the directions of maximum variance in the data. 
#This means, we can see influence on each of the components by variables

loadings = pca_model.components_
num_pc = pca_model.n_features_
pc_list = ["PC"+str(i) for i in list(range(1, num_pc+1))]
loadings_df = pd.DataFrame.from_dict(dict(zip(pc_list, loadings)))
loadings_df['variable'] = X.columns
loadings_df = loadings_df.set_index('variable')
loadings_df


# In[48]:


# get correlation matrix plot for loadings
f, ax = plt.subplots(figsize=(30, 10))
ax = sn.heatmap(loadings_df, annot=True, cmap='vlag')
# plt.savefig(r'C:\Users\monster\Desktop\Variables\loadings_tal_pca.png', bbox_inches='tight', dpi=600)
plt.show()


# A different way of plotting it

# In[49]:


f, ax = plt.subplots(figsize=(20, 10))
ax = sn.heatmap(pca_model.components_,
                 cmap='vlag',
                 yticklabels=[ "PCA"+str(x) for x in range(1,pca_model.n_components_+1)],
                 xticklabels=list(X.columns),
                 cbar_kws={"orientation": "vertical"})
# plt.savefig(r'C:\Users\monster\Desktop\Variables\loadings_pca.png', bbox_inches='tight')
ax.set_aspect("equal")


# 
# 
# Bioplot contains PCA loading plot which shows how much each variables effects a principal component.
# 
# PCA Loading Plot: All vectors start at origin and their projected values on components explains how much influence they have on that component. Angles between vectors indicate whether there is correlation between them - smaller angles tell about stronger correlation.

# In[50]:


def myplot(score,coeff,labels=None):
    xs = score[:,0]
    ys = score[:,1]
    n = coeff.shape[0]
    scalex = 1.0/(xs.max() - xs.min())
    scaley = 1.0/(ys.max() - ys.min())
    scatter = plt.scatter(xs * scalex,ys * scaley, c=y_train)
    
    for i in range(n):
        plt.arrow(0, 0, coeff[i,0], coeff[i,1],color = 'r',alpha = 0.3)
        if labels is None:
            plt.text(coeff[i,0]* 1.15, coeff[i,1] * 1.15, "Var"+str(i+1), color = 'green', ha = 'center', va = 'center')
        else:
            plt.text(coeff[i,0]* 1.15, coeff[i,1] * 1.15, labels[i], color = 'g', ha = 'center', va = 'center')
 
    labels = np.unique(y)
    handles = [plt.Line2D([],[],marker="o", ls="", 
                      color=scatter.cmap(scatter.norm(yi))) for yi in labels]
    plt.legend(handles, labels, loc=7, title='Class', title_fontsize='xx-large', fontsize='xx-large')
    plt.xlabel("PC{}".format(1))
    plt.ylabel("PC{}".format(2))
    plt.grid()
    

    
f, ax = plt.subplots(figsize=(30,30))
myplot(pc_train_data[:,0:2],np.transpose(pca_model.components_[0:2, :]),list(X.columns))
# plt.savefig(r'C:\Users\monster\Desktop\Variables\loadings_plot_pca.png', bbox_inches='tight', dpi=600)
plt.show()


# Transforming testing data

# In[51]:


standardized_test_data=scaler.transform(X_test)


# In[52]:


pc_test_data=pca_model.transform(standardized_test_data)


# In[61]:


from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import RandomizedSearchCV
from sklearn.neural_network import MLPClassifier


# In[62]:


model_xgb = xgb.XGBClassifier(#colsample_bytree=0.9, objective = 'binary:logistic',
                             learning_rate=0.02, max_depth=6, eval_metric = 'auc',
                             min_child_weight=10, n_estimators=842,
                             #subsample=0.7, silent=1,
                             random_state =0, nthread = -1)

model_rf = RandomForestClassifier(random_state = 0)
model_clf1 = MLPClassifier(random_state=1, max_iter=300)


# In[63]:


xgb = model_xgb.fit(X_train, y_train)
rf =model_rf.fit(X_train, y_train)
clf1=model_clf1.fit(X_train, y_train)

y_train_pred_xgb = xgb.predict(X_train)
y_test_pred_xgb = xgb.predict(X_test)

y_train_pred_rf = rf.predict(X_train)
y_test_pred_rf = rf.predict(X_test)

y_train_pred_clf1 = clf1.predict(X_train)
y_test_pred_clf1 = clf1.predict(X_test)


# In[64]:


print ('AUC: %.4f' % metrics.roc_auc_score(y_train_pred_clf1,y_train))
print ('ACC: %.4f' % metrics.accuracy_score(y_train_pred_clf1,y_train))
print ('Recall: %.4f' % metrics.recall_score(y_train_pred_clf1,y_train))
print ('F1-score: %.4f' %metrics.f1_score(y_train_pred_clf1,y_train))
print ('Precesion: %.4f' %metrics.precision_score(y_train_pred_clf1,y_train))
print(metrics.confusion_matrix(y_train_pred_clf1,y_train))


# In[65]:


print ('AUC: %.4f' % metrics.roc_auc_score(y_test_pred_clf1,y_test))
print ('ACC: %.4f' % metrics.accuracy_score(y_test_pred_clf1,y_test))
print ('Recall: %.4f' % metrics.recall_score(y_test_pred_clf1,y_test))
print ('F1-score: %.4f' %metrics.f1_score(y_test_pred_clf1,y_test))
print ('Precesion: %.4f' %metrics.precision_score(y_test_pred_clf1,y_test))
print(metrics.confusion_matrix(y_test_pred_clf1,y_test))


# In[66]:


print ('AUC: %.4f' % metrics.roc_auc_score(y_train_pred_xgb,y_train))
print ('ACC: %.4f' % metrics.accuracy_score(y_train_pred_xgb,y_train))
print ('Recall: %.4f' % metrics.recall_score(y_train_pred_xgb,y_train))
print ('F1-score: %.4f' %metrics.f1_score(y_train_pred_xgb,y_train))
print ('Precesion: %.4f' %metrics.precision_score(y_train_pred_xgb,y_train))
print(metrics.confusion_matrix(y_train_pred_xgb,y_train))


# In[67]:


print ('AUC: %.4f' % metrics.roc_auc_score(y_test_pred_xgb,y_test))
print ('ACC: %.4f' % metrics.accuracy_score(y_test_pred_xgb,y_test))
print ('Recall: %.4f' % metrics.recall_score(y_test_pred_xgb,y_test))
print ('F1-score: %.4f' %metrics.f1_score(y_test_pred_xgb,y_test))
print ('Precesion: %.4f' %metrics.precision_score(y_test_pred_xgb,y_test))
print(metrics.confusion_matrix(y_test_pred_xgb,y_test))


# In[68]:


print ('AUC: %.4f' % metrics.roc_auc_score(y_train_pred_rf,y_train))
print ('ACC: %.4f' % metrics.accuracy_score(y_train_pred_rf,y_train))
print ('Recall: %.4f' % metrics.recall_score(y_train_pred_rf,y_train))
print ('F1-score: %.4f' %metrics.f1_score(y_train_pred_rf,y_train))
print ('Precesion: %.4f' %metrics.precision_score(y_train_pred_rf,y_train))
print(metrics.confusion_matrix(y_train_pred_rf,y_train))


# In[69]:


print ('AUC: %.4f' % metrics.roc_auc_score(y_test_pred_rf,y_test))
print ('ACC: %.4f' % metrics.accuracy_score(y_test_pred_rf,y_test))
print ('Recall: %.4f' % metrics.recall_score(y_test_pred_rf,y_test))
print ('F1-score: %.4f' %metrics.f1_score(y_test_pred_rf,y_test))
print ('Precesion: %.4f' %metrics.precision_score(y_test_pred_rf,y_test))
print(metrics.confusion_matrix(y_test_pred_rf,y_test))


# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:




